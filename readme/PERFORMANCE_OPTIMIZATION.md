# Otimiza√ß√µes de Performance - M√©tricas SLA

## üìä An√°lise do Problema

O dashboard estava lento ao carregar m√©tricas de SLA porque executava m√∫ltiplas queries pesadas sequencialmente.

### Gargalos Identificados

#### 1. **Problema N+1 em `get_sla_compliance_24h`**

- **Antes**: Para cada chamado ativo, fazia uma chamada a `SLACalculator.get_sla_status()`
- **Impacto**: 500 chamados = 500+ queries ao banco
- **Sintoma**: P√°gina congelava por 10+ segundos

#### 2. **Problema N+1 em `get_sla_compliance_mes`**

- **Antes**: Chamava `get_sla_config_by_priority()` para cada chamado
- **Impacto**: M√∫ltiplas queries desnecess√°rias
- **Sintoma**: SLA "Este m√™s" demorava muito

#### 3. **Execu√ß√£o Sequencial no Frontend**

- **Antes**: Carregava todas as m√©tricas em uma √∫nica chamada
- **Impacto**: Frontend bloqueado esperando m√©tricas SLA lentas
- **Sintoma**: Usu√°rio via loading por tempo prolongado

## ‚úÖ Solu√ß√µes Implementadas

### 1. Cache em Mem√≥ria com TTL

**Arquivo**: `backend/ti/services/metrics.py`

```pythonf
class MetricsCache:
    _cache = {}
    _ttl_seconds = 30  # Cache por 30 segundos

    @classmethod
    def get(cls, key):
        # Retorna valor se ainda est√° v√°lido (menor que 30s)

    @classmethod
    def set(cls, key, value):
        # Armazena com timestamp
```

**Benef√≠cio**:

- ‚úÖ Mesma requisi√ß√£o em < 1s (se em cache)
- ‚úÖ Sem overhead de rede adicional
- ‚úÖ TTL de 30s = dados sempre frescos

### 2. Elimina√ß√£o de N+1 Queries

**Arquivo**: `backend/ti/services/metrics.py`

#### Antes (‚ùå 500+ queries):

```python
for chamado in chamados_ativos:
    sla_status = SLACalculator.get_sla_status(db, chamado)  # Query por chamado!
```

#### Depois (‚úÖ 2 queries):

```python
# Query 1: Carrega TODAS as configs de SLA uma vez
sla_configs = {config.prioridade: config for config in db.query(...).all()}

# Query 2: Carrega todos os chamados uma vez
chamados_ativos = db.query(Chamado).filter(...).all()

# Itera sem mais queries
for chamado in chamados_ativos:
    sla_config = sla_configs.get(chamado.prioridade)  # Dicion√°rio, n√£o query!
```

**Resultado**:

- ‚ùå Antes: ~500 queries
- ‚úÖ Depois: 2 queries

### 3. Carregamento em Duas Etapas (Frontend)

**Arquivo**: `frontend/src/pages/sectors/ti/admin/Overview.tsx`

#### Novo fluxo:

1. **Etapa 1 (R√°pida - 100ms)**: Carrega m√©tricas b√°sicas
   - `GET /metrics/dashboard/basic` ‚Üí Instant√¢neo
   - Mostra: Chamados hoje, Ativos, Compara√ß√£o ontem
   - Usu√°rio v√™ informa√ß√µes imediatamente

2. **Etapa 2 (Lenta - 5s com cache, 15s sem)**: Carrega SLA
   - `GET /metrics/dashboard/sla` ‚Üí Com cache
   - Mostra: SLA%, Tempo de resposta, Gr√°ficos
   - Enquanto isso, usu√°rio j√° v√™ dados b√°sicos

**Benef√≠cio**:

- ‚úÖ Percep√ß√£o de velocidade: "Algo est√° acontecendo"
- ‚úÖ Usu√°rio n√£o fica esperando tela em branco
- ‚úÖ Melhor UX mesmo com dados lentos

### 4. √çndices de Banco de Dados

**Arquivo**: `backend/ti/scripts/create_performance_indices.py`

```sql
CREATE INDEX idx_chamado_status ON chamado(status);
CREATE INDEX idx_chamado_data_abertura ON chamado(data_abertura);
CREATE INDEX idx_chamado_prioridade ON chamado(prioridade);
CREATE INDEX idx_chamado_status_data ON chamado(status, data_abertura);
CREATE INDEX idx_historico_chamado_created ON historico_status(chamado_id, created_at);
```

**Executar**:

```bash
cd backend
python -m ti.scripts.create_performance_indices
```

## üìà Resultados Esperados

| M√©trica          | Antes  | Depois     | Melhoria          |
| ---------------- | ------ | ---------- | ----------------- |
| Primeira carga   | 15-20s | 100ms + 5s | **60-80%**        |
| Segunda carga    | 15-20s | <500ms     | **95%+**          |
| Queries ao banco | 500+   | 2-3        | **99%**           |
| Uso de CPU       | Alto   | Baixo      | **Significativo** |

## üîç Monitoramento

### Verificar se est√° funcionando:

1. **Abrir DevTools (F12)**
2. **Aba Network**
3. **Recarregar p√°gina**
4. Ver chamadas:
   - ‚úÖ `/api/metrics/dashboard/basic` ‚Üí ~50-100ms
   - ‚úÖ `/api/metrics/dashboard/sla` ‚Üí ~500-1000ms (cache) / 5-15s (sem cache)

### Logs de Performance:

```python
# No backend, verificar logs para confirmar cache:
print("Cache hit rate:")
print(f"- sla_compliance_24h: X requisi√ß√µes")
print(f"- sla_compliance_mes: Y requisi√ß√µes")
```

## ‚öôÔ∏è Ajustes Futuros

### Se ainda estiver lento:

1. **Aumentar TTL do cache** ‚Üí `_ttl_seconds = 60` (1 minuto)
2. **Usar Redis** ‚Üí Substituir `MetricsCache` por Redis para cache distribu√≠do
3. **Pr√©-calcular m√©tricas** ‚Üí Usar Celery/APScheduler para calcular em background

### Se quiser dados mais frescos:

1. **Reduzir TTL** ‚Üí `_ttl_seconds = 10` (10 segundos)
2. **Usar WebSocket** ‚Üí Atualizar m√©tricas em tempo real

## üìù Checklist de Implementa√ß√£o

- [x] Criar `MetricsCache` class
- [x] Otimizar `get_sla_compliance_24h` (eliminar N+1)
- [x] Otimizar `get_sla_compliance_mes` (eliminar N+1)
- [x] Separar endpoints: `/dashboard/basic` e `/dashboard/sla`
- [x] Atualizar frontend para carregar em etapas
- [x] Criar script de √≠ndices
- [ ] Executar script de √≠ndices no banco
- [ ] Testar em produ√ß√£o
- [ ] Monitorar performance

## üöÄ Para Produ√ß√£o

1. **Executar script de √≠ndices**:

   ```bash
   python backend/ti/scripts/create_performance_indices.py
   ```

2. **Testar antes de deploys**:

   ```bash
   # Abra DevTools e verifique tempos de carregamento
   # GET /api/metrics/dashboard/basic deve ser < 200ms
   # GET /api/metrics/dashboard/sla deve ser < 1s (com cache)
   ```

3. **Monitorar em produ√ß√£o**:
   - Observar tempo de resposta dos endpoints
   - Verificar CPU durante picos de uso
   - Ajustar TTL de cache conforme necess√°rio
